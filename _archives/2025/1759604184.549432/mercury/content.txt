top of pageUniversity of SaskatchewanTalk title to be announced Julita Vassileva is a professor at the University of Saskatchewan, focusing on human-centered AI . Her research spans user modeling, personalization, recommender systems, intelligent tutoring systems, multi-agent systems, social computing, trust and reputation mechanisms, persuasive technology, and behavior change. She has nearly 300 publications and has supervised over 60 graduate students. Additionally, she is the section editor of Frontiers in AI: Human Learning and Behaviour Change, co-editor of the HCI section of PeerJ Computer Science, and a member of the editorial boards of User Modeling and User-Adapted Interaction, International Journal of AI in Education, and ACM Transactions of Social Computing.Talk title to be announced Dr. Gideon Christian is an Associate Professor and University Research Chair in AI and Law at the University of Calgary. Prior to joining the University of Calgary, he was technology lawyer with the federal Department of Justice where he deployed technology in high profile litigation involving the Government of Canada. His research interests are in artificial intelligence and law, legal impacts of new and emerging technologies among other areas. Dr. Christian’s research seeks to identify elements of racial bias in laws, policies and in emerging technologies. His current research seeks to develop the concept of algorithmic racism which is defined as race-based bias arising from the use of AI-powered tools in the analysis of data in decision making resulting in unfair outcomes to individuals from a particular segment of the society characterised by race. Dr. Christian has appeared before the House of Commons Committee on Citizenship and Immigration (CIMM) as an expert in the use of AI in immigration decisions. He was the Ontario Bar Association 2024 Chief Justice of Ontario Fellow in Research. He was named by the Calgary Herald as one of the top 20 Compelling Calgarians in 2024, and was awarded the ITL Trailblazer in Technology Award in 2025.Talk title to be announced Dr. Nils Daniel Forkert, PhD, is a Professor at the University of Calgary in the Departments of Radiology and Clinical Neurosciences. He received his German diploma in Computer Science in 2009 from the University of Hamburg, his master’s degree in medical physics in 2012 from the Technical University of Kaiserslautern, his PhD in computer science in 2013 from the University of Hamburg, and completed a postdoctoral fellowship at Stanford University before joining the University of Calgary as an Assistant Professor in 2014. He is an imaging and machine learning scientist who develops new image processing methods, predictive algorithms, and software tools for the analysis of medical data. This includes the extraction of clinically relevant parameters and biomarkers from medical data describing the morphology and function of organs with the aim of supporting clinical studies and preclinical research as well as developing computer-aided diagnosis and patient-specific, precision-medicine, prediction models using machine learning based on multi-modal medical data. Dr. Forkert is a Canada Research Chair (Tier 2) in Medical Image Analysis, and Director of the Child Health Data Science Program of the Alberta Children's Hospital Research Institute as well as the Theme Lead for Machine Learning in Neuroscience of the Hotchkiss Brain Institute at the University of Calgary. He has published over 210 peer-reviewed manuscripts, over 90 full-length proceedings papers, 1 book, and 2 book chapters and has received major funding from the Canadian Institutes of Health Research (CIHR), Natural Sciences and Engineering Research Council, the Heart and Stroke Foundation, Calgary Foundation, and the National Institutes of Health as a PI or co-PI.Director, Fraser Health AuthorityTalk Title: Responsible Innovation: Revolutionizing Healthcare with Generative AI Hamidreza Eslami is a seasoned data science leader with over a decade of experience applying advanced analytics in both service and healthcare environments. With a background in Industrial Engineering and Management Science, he brings a systems-thinking approach to solving complex operational and clinical challenges. For the past eight years, he has played a pivotal role at Fraser Health Authority, where he strategically leads the development and deployment of AI solutions that have measurably improved care delivery and system performance for nearly two million residents. His work spans machine learning, operations research, and the responsible use of Generative AI - including applications in clinical documentation, decision support, and virtual assistants - ensuring that innovation translates into meaningful, safe, and equitable outcomes. Hamidreza also contributes to workforce development as a faculty member at the British Columbia Institute of Technology’s School of Business, where he mentors future professionals in data-driven decision-making.CIFAR AI Chair, University of British ColumbiaTalk Title: Foundation Models in Healthcare: Advances, Pitfalls, and Path Forward Dr. Xiaoxiao Li is currently an assistant professor in the Department of Electrical and Computer Engineering at the University of British Columbia, a faculty member at Vector Institute. Dr. Li is recognized as a Canada Research Chair (Tier II) in responsible AI and a Cifar AI Chair. Dr. Li’s research interests primarily lie at the intersection of AI and healthcare, theory and techniques for artificial general intelligence (AGI), and AI trustworthiness. Dr. Li aims to develop the next-generation responsible AI algorithms and systems. Professor Philip M. Newton, Ph.D. is the Head of Learning and Teaching at Swansea University Medical School in the United Kingdom, where he is also programme director for the Research in Health Professions Education programme. He teaches neuroscience to medical students and the principles of evidence-based education to anyone who will listen. Phil received his Ph.D from the University of Leeds in the UK where he studied Cell Biology. He was a postdoc and then junior faculty at the University of California, San Francisco where he studied genetic models of posttraumatic stress disorder, alcoholism and addiction to try and determine the neurological basis for these disorders. In addition to his research on neuroscience, he also investigates academic integrity and the ethical use of artificial intelligence by higher education students.Associate Professor, McGill University, MilaTalk Title: Fairness in Reinforcement Learning with Bisimulation MetricsBio Dr. David Meger is an Associate Professor at the School of Computer Science at McGill University. He is Co-Director of the Mobile Robotics Laboratory, a member of the Centre for Intelligent Machines, co-PI in the NSERC Canadian Robotics Network and an Associate Member of Mila, the Quebec AI Institute. David’s PhD research at the University of British Columbia led to Curious George, a robot that won several international contests in live object search. During his postdoctoral research at McGill, he pioneered the use of RL in underwater control, leading to a best paper nomination at ICRA. The research of his current group spans 3D computer vision, visual navigation, imitation learning, RL for continuous control, all applied to indoor autonomy and field robotics. Prof. Meger’s research has led to state-of-the-art software solutions that are widely used around the world and reimplemented in leading AI toolkits, such as TD3, an RL method to learn behaviors on continuous control systems, and BCQ, an offline RL approach. David has been awarded the CIPPRS Award for Service to the Canadian Computer Vision community in 2017. He served as co-chair of the Computer and Robot Vision conference in 2013 and 2014 and was local arrangements chair of ICRA 2019. Prof. Meger was the Co-General Chair of the CS-CAN Co-Located Conferences including the Conference on Robot Vision and the Canadian AI Conference in 2023. Professor, University of CalgaryTalk Title: LLMs for Expert Elicitation in Probabilistic Causal Modeling Dr. Yanushkevich is an electrical engineer focusing on biometrics. She has also applied machine learning to logic design and is known for her earlier research in reversible computing. She is a full professor in the Department of Electrical and Software Engineering at the University of Calgary, where she heads the Biometric Technologies Laboratory.  Dr. Yanushkevich's work emphasizes the development of decision support and risk assessment strategies that enhance transparency and trust in AI systems. Her contributions to explainable machine learning are instrumental in advancing the field toward more accountable and interpretable AI solutions. She is also the Associate Dean for Research in the Schulich School of Engineering here at the University of Calgary.Associate Professor, Dalhousie UniversityTalk Title: Latent Concept-Based Explanation of NLP ModelsBio Dr. Sajjad is an Associate Professor in the Faculty of Computer Science and Director of HyperMatrix at Dalhousie University, Halifax, Canada. He is an AI researcher with domain expertise in Natural Language Processing and Safe and Trustworthy AI. Moreover, he is a consultant and a mentor blended with entrepreneurial interests. He is a leading researcher in the field of explainable machine learning, with a focus on large language models. Dr. Sajjad has contributed to the development of methods like Latent Concept Attribution, which aim to provide deeper insights into the decision-making processes of deep learning models.Assistant Professor, University of Calgary, Mila, CIFAR AI ChaiTalk Title: Explainability in Machine LearningBio Samira is an Assistant Professor at the University of Calgary, an Adjunct Professor at École de technologie supérieure and an Adjunct Professor at McGill University. She is a member of the Quebéc AI Institute (Mila) and holds a Canada CIFAR AI Chair. Samira received her Ph.D. in Computer Engineering from Polytechnique Montréal/Mila with an award for the best thesis in the department. Samira also worked as a Postdoctoral Fellow at McGill and as a Researcher at Microsoft Research Montréal.Samira’s pioneering work in visual reasoning includes the two well-known datasets “Something Something” and “FigureQA”. Her current focus is on enhancing generalization and interpretability in machine learning, with a particular focus on large language models and sequential decision making. Samira also works on diverse applications of machine learning, e.g. for drug dosage recommendation, medical imaging, or environmental forecasting. Samira’s work has been published in top-tier venues, such as NeurIPS, ICLR, ICML, ICCV, CVPR, TMLR and CoRL. She is a recipient of the Ten-Year Technical Impact Runner-Up Award at the 25th ACM International Conference on Multimodal Interaction.Assistant Professor, ETS Montreal, MilaTalk Title: Overview of Interpretability and Explainability Methods, and Practical ConsiderationsBio Ulrich Aïvodji is an Assistant Professor at the École de Technologie Supérieure (ÉTS) in Montreal. His research focuses on the development of trustworthy AI systems, with focus on key topics such as privacy, security, algorithmic fairness, explainability, and interpretability. He is an associate academic member of Mila – Quebec Artificial Intelligence Institute and a regular member of OBVIA (International Observatory on the Societal Impacts of AI and Digital Technology). Additionally, he contributes as a lead expert to the CIFAR-Mila AI Insights for Policymakers group, participating in discussions on AI governance and policy. He completed his PhD in Computer Science from the University of Toulouse III – Paul Sabatier and LAAS-CNRS, and was previously a postdoctoral researcher at the Université du Québec à Montréal (UQAM).bottom of page